@article{amonkarDifferentialEffectsClimate2023a,
  title = {Differential {{Effects}} of {{Climate Change}} on {{Average}} and {{Peak Demand}} for {{Heating}} and {{Cooling}} across the {{Contiguous USA}}},
  author = {Amonkar, Yash and {Doss-Gollin}, James and Farnham, David J. and Modi, Vijay and Lall, Upmanu},
  year = {2023},
  month = nov,
  journal = {Communications Earth \& Environment},
  volume = {4},
  number = {1},
  pages = {1--9},
  issn = {2662-4435},
  doi = {10.1038/s43247-023-01048-1},
  urldate = {2023-11-01},
  abstract = {While most electricity systems are designed to handle peak demand during summer months, long-term energy pathways consistent with deep decarbonization generally electrify building heating, thus increasing electricity demand during winter. A key question is how climate variability and change will affect peak heating and cooling demand in an electrified future. We conduct a spatially explicit analysis of trends in temperature-based proxies of electricity demand over the past 70{\textbackslash}textbackslash,years. Average annual demand for heating (cooling) decreases (increases) over most of the contiguous US. However, while climate change drives robust increases in peak cooling demand, trends in peak heating demand are generally smaller and less robust. Because the distribution of temperature exhibits a long left tail, severe cold snaps dominate the extremes of thermal demand. As building heating electrifies, system operators must account for these events to ensure reliability.}
}

@article{arribasClimateRiskAssessment2022a,
  title = {Climate {{Risk Assessment Needs Urgent Improvement}}},
  author = {Arribas, Alberto and Fairgrieve, Ross and Dhu, Trevor and Bell, Juliet and Cornforth, Rosalind and Gooley, Geoff and Hilson, Chris J. and Luers, Amy and Shepherd, Theodore G. and Street, Roger and Wood, Nick},
  year = {2022},
  month = aug,
  journal = {Nature Communications},
  volume = {13},
  number = {1},
  pages = {4326},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-31979-w},
  urldate = {2023-03-23},
  abstract = {Existing constraints in current climate risk assessments make them inappropriate to effectively assess the true exposure of society and businesses to climate-related risk. Using the key constraints to guide a conceptual framework, we identify four cross-cutting and inter-related critical paths for improvement.}
}

@article{arrowDeterminingBenefitsCosts2013b,
  title = {Determining {{Benefits}} and {{Costs}} for {{Future Generations}}},
  author = {Arrow, K. and Cropper, M. and Gollier, C. and Groom, B. and Heal, G. and Newell, R. and Nordhaus, W. and Pindyck, R. and Pizer, W. and Portney, P. and Sterner, T. and Tol, R. S. J. and Weitzman, M.},
  year = {2013},
  month = jul,
  journal = {Science},
  volume = {341},
  number = {6144},
  pages = {349--350},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1235665},
  urldate = {2020-04-30},
  abstract = {In economic project analysis, the rate at which future benefits and costs are discounted relative to current values often determines whether a project passes the benefit-cost test. This is especially true of projects with long time horizons, such as those to reduce greenhouse gas (GHG) emissions. Whether the benefits of climate policies, which can last for centuries, outweigh the costs, many of which are borne today, is especially sensitive to the rate at which future benefits are discounted. This is also true of other policies, e.g., affecting nuclear waste disposal or the construction of long-lived infrastructure. The United States and others should consider adopting a different approach to estimating costs and benefits in light of uncertainty. The United States and others should consider adopting a different approach to estimating costs and benefits in light of uncertainty.}
}

@article{bankesExploratoryModelingPolicy1993b,
  title = {Exploratory {{Modeling}} for {{Policy Analysis}}},
  author = {Bankes, Steve},
  year = {1993},
  month = jun,
  journal = {Operations Research},
  volume = {41},
  number = {3},
  pages = {435--449},
  issn = {0030-364X},
  doi = {10/c7rgcr},
  urldate = {2019-02-19},
  abstract = {Exploratory modeling is using computational experiments to assist in reasoning about systems where there is significant uncertainty. While frequently confused with the use of models to consolidate knowledge into a package that is used to predict system behavior, exploratory modeling is a very different kind of use, requiring a different methodology for model development. This paper distinguishes these two broad classes of model use describes some of the approaches used in exploratory modeling, and suggests some technological innovations needed to facilitate it.}
}

@article{bonnafousWaterRiskIndex2017b,
  title = {A {{Water Risk Index}} for {{Portfolio Exposure}} to {{Climatic Extremes}}: {{Conceptualization}} and an {{Application}} to the {{Mining Industry}}},
  author = {Bonnafous, Luc and Lall, Upmanu and Siegel, Jason},
  year = {2017},
  journal = {Hydrology and Earth System Sciences},
  volume = {21},
  number = {4},
  pages = {2075--2106},
  doi = {10/f96k67},
  abstract = {Corporations, industries and non-governmental organizations have become increasingly concerned with growing water risks in many parts of the world. Most of the focus has been on water scarcity and competition for the resource between agriculture, urban users, ecology and industry. However, water risks are multi-dimensional. Water-related hazards include flooding due to extreme rainfall, persistent drought and pollution, either due to industrial operations themselves, or to the failure of infrastructure. Most companies have risk management plans at each operational location to address these risks to a certain design level. The residual risk may or may not be managed, and is typically not quantified at a portfolio scale, i.e. across many sites. Given that climate is the driver of many of these extreme events, and there is evidence of quasi-periodic climate regimes at inter-annual and decadal timescales, it is possible that a portfolio is subject to persistent, multi-year exceedances of the design level. In other words, for a multi-national corporation, it is possible that there is correlation in the climate-induced portfolio water risk across its operational sites as multiple sites may experience a hazard beyond the design level in a given year. Therefore, from an investor's perspective, a need exists for a water risk index that allows for an exploration of the possible space and/or time clustering in exposure across many sites contained in a portfolio. This paper represents a first attempt to develop an index for financial exposure of a geographically diversified, global portfolio to the time-varying risk of climatic extremes using long daily global rainfall datasets derived from climate re-analysis models. Focusing on extreme daily rainfall amounts and using examples from major mining companies, we illustrate how the index can be developed. We discuss how companies can use it to explore their corporate exposure, and what they may need to disclose to investors and regulators to promote transparency as to risk exposure and mitigation efforts. For the examples of mining companies provided, we note that the actual exposure is substantially higher than would be expected in the absence of space and time correlation of risk as is usually tacitly assumed. We also find evidence for the increasing exposure to climate-induced risk, and for decadal variability in exposure. The relative vulnerability of different portfolios to multiple extreme events in a given year is also demonstrated.}
}

@article{busbyCascadingRisksUnderstanding2021a,
  title = {Cascading {{Risks}}: {{Understanding}} the 2021 {{Winter Blackout}} in {{Texas}}},
  author = {Busby, Joshua W. and Baker, Kyri and Bazilian, Morgan D. and Gilbert, Alex Q. and Grubert, Emily and Rai, Varun and Rhodes, Joshua D. and Shidore, Sarang and Smith, Caitlin A. and Webber, Michael E.},
  year = {2021},
  month = jul,
  journal = {Energy Research \& Social Science},
  volume = {77},
  pages = {102106},
  issn = {2214-6296},
  doi = {10.1016/j.erss.2021.102106},
  urldate = {2021-06-03},
  abstract = {The Texas freeze of February 2021 left more than 4.5 million customers (more than 10 million people) without electricity at its peak, some for several days. The freeze had cascading effects on other services reliant upon electricity including drinking water treatment and medical services. Economic losses from lost output and damage are estimated to be \$130 billion in Texas alone. In the wake of the freeze, there has been major fallout among regulators and utilities as actors sought to apportion blame and utilities and generators began to settle up accounts. This piece offers a retrospective on what caused the blackouts and the knock-on effects on other services, the subsequent financial and political effects of the freeze, and the implications for Texas and the country going forward. Texas failed to sufficiently winterize its electricity and gas systems after 2011. Feedback between failures in the two systems made the situation worse. Overall, the state faced outages of 30 GW of electricity as demand reached unprecedented highs. The gap between production and demand forced the non-profit grid manager, the Electric Reliability Council of Texas (ERCOT), to cut off supply to millions of customers or face a systems collapse that by some accounts was minutes away. The 2021 freeze suggests a need to rethink the state's regulatory approach to energy to avoid future such outcomes. Weatherization, demand response, and expanded interstate interconnections are potential solutions Texas should consider to avoid generation losses, reduce demand, and tap neighboring states' capacity.}
}

@misc{condonClimateServicesBusiness2023a,
  type = {{{SSRN Scholarly Paper}}},
  title = {Climate {{Services}}: {{The Business}} of {{Physical Risk}}},
  author = {Condon, Madison},
  year = {2023},
  month = mar,
  urldate = {2023-03-22},
  abstract = {A growing number of investors, insurers, financial services providers, and nonprofits rely on information about localized physical climate risks, like floods, hurricanes, and wildfires. The outcomes of these risk projections have significant consequences in the economy, including allocating investment capital, impacting housing prices and demographic shifts, and prioritizing adaptation infrastructure projects. The climate risk information available to individual citizens and municipalities, however, is limited and expensive to access. Further, many providers of climate services use black box models that make overseeing the scientific rigor of their methodologies impossible--- a concern given scientific critiques that many may be obfuscating the uncertainty in their projections. Municipalities that want to challenge insurance and bond rating determinations must rally significant resources for modeling and data, a scattershot policing method at best. And when companies have access to sophisticated modeling about future impacts--- some of them potentially devastating for entire communities---the decision to share that information has been largely left up to the corporation.This Article argues that actionable and transparent information about our climate-changed future is a public good that the private sector cannot be depended upon to provide equitably or reliably. Further, all private climate services rely on upstream climate data and models that were collected and produced by an enormous network of public institutions. There are important lessons to be learned from the recent success of special interests in pressing for the privatization of weather data and services---a trend that has knock-on effects for weather forecasts globally. This Article urges state and federal governments to invest in their own climate services capacity at a scale not currently contemplated. Risk assessments lacking a scientific basis can lead to maladaptation across the economy. While it is a potentially limited matter of consumer protection or tort liability when a consultancy over-promises its analytical capabilities, it is a much larger problem if regulators themselves misunderstand the limits of uncertainty when designing risk oversight.},
  howpublished = {https://papers.ssrn.com/abstract=4396826}
}

@article{condonMarketMyopiaClimate2021b,
  title = {Market {{Myopia}}'s {{Climate Bubble}}},
  author = {Condon, Madison},
  year = {2021},
  month = feb,
  doi = {10.2139/ssrn.3782675},
  urldate = {2021-04-13},
  abstract = {A growing number of financial institutions, ranging from BlackRock to the Bank of England, have warned that markets may not be accurately incorporating climate change-related risks into asset prices. This Article seeks to explain how this mispricing can exist at the level of individual assets drawing from scholarship on corporate governance and the mechanisms of market (in)efficiency. Market actors: 1. Lack the fine-grained asset-level data they need in order to assess risk exposure; 2. Continue to rely on outdated means of assessing risk; 3. Have misaligned incentives resulting in climate-specific agency costs; 4. Have myopic biases exacerbated by climate change misinformation; and 5. Are impeded by captured regulators distorting the market. Further, trends in institutional share ownership reinforce apathy regarding assessment of firm-specific fundamentals, especially over long-term horizons. This underpricing of corporate climate risk contributes to the negative effects of climate change itself, as the mispricing of risk in the present leads to a misallocation of investment capital, hindering future adaptation and subsidizing future fossil combustion. These risks could accumulate to the macroeconomic scale, generating a systemic risk to the financial system. While a broad array of government interventions are necessary to mitigate climate related financial risks, this Article focuses on proposals for corporate governance and securities regulation---and their limits. Signals from the Biden Administration suggest that mandatory climate risk disclosure regulation from the Securities and Exchange Commission is forthcoming. This Article argues that climate risk disclosure is necessary, though alone not sufficient, to address the widespread disregard of corporate climate exposure.}
}

@article{decontoContributionAntarcticaFuture2016a,
  title = {Contribution of {{Antarctica}} to {{Past}} and {{Future Sea-Level Rise}}},
  author = {DeConto, Robert M. and Pollard, David},
  year = {2016},
  month = mar,
  journal = {Nature},
  volume = {531},
  number = {7596},
  pages = {591--597},
  issn = {1476-4687},
  doi = {10.1038/nature17145},
  urldate = {2020-02-20},
  abstract = {Climate and ice-sheet modelling that includes ice fracture dynamics reveals that Antarctica could contribute more than a metre of sea-level rise by 2100 and more than 13{\textbackslash}textbackslash,metres by 2500, if greenhouse gas emissions continue unabated.}
}

@article{demoelEvaluatingEffectFlood2014a,
  title = {Evaluating the {{Effect}} of {{Flood Damage-Reducing Measures}}: {{A Case Study}} of the {{Unembanked Area}} of {{Rotterdam}}, the {{Netherlands}}},
  author = {{de Moel}, Hans and {van Vliet}, Mathijs and Aerts, Jeroen C. J. H.},
  year = {2014},
  month = jun,
  journal = {Regional Environmental Change},
  volume = {14},
  number = {3},
  pages = {895--908},
  issn = {1436-378X},
  doi = {10.1007/s10113-013-0420-z},
  urldate = {2021-03-16},
  abstract = {Empirical evidence of increasing flood damages and the prospect of climatic change has initiated discussions in the flood management community on how to effectively manage flood risks. In the Netherlands, the framework of multi-layer safety (MLS) has been introduced to support this risk-based approach. The MLS framework consists of three layers: (i) prevention, (ii) spatial planning and (iii) evacuation. This paper presents a methodology to evaluate measures in the second layer, such as wet proofing, dry proofing or elevating buildings. The methodology uses detailed land-use data for the area around the city of Rotterdam (up to building level) that has recently become available. The vulnerability of these detailed land-use classes to flooding is assessed using the stage--damage curves from different international models. The methodology is demonstrated using a case study in the unembanked area of Rotterdam in the Netherlands, as measures from the second layer may be particularly effective there. The results show that the flood risk in the region is considerable: EUR 36 million p.a. A large part (almost 60 \%) of this risk results from industrial land use, emphasising the need to give this category more attention in flood risk assessments. It was found that building level measures could substantially reduce flood risks in the region because of the relatively low inundation levels of buildings. Risk to residential buildings would be reduced by 40 \% if all buildings would be wet-proofed, by 89 \% if all buildings would be dry-proofed and elevating buildings over 100 cm would render the risk almost zero. While climate change could double the risk in 2100, such building level measures could easily nullify this effect. Despite the high potential of such measures, actual implementation is still limited. This is partly caused by the lack of knowledge regarding these measures by most Dutch companies and the legal impossibility for municipalities to enforce most of these measures as they would go beyond the building codes established at the national level.}
}

@article{deneufvilleRealOptionsSpreadsheet2006b,
  title = {Real {{Options}} by {{Spreadsheet}}: {{Parking Garage Case Example}}},
  author = {{de Neufville}, Richard and Scholtes, Stefan and Wang, Tao},
  year = {2006},
  journal = {Journal of Infrastructure Systems},
  volume = {12},
  number = {2},
  pages = {107--111},
  doi = {10.1061/(asce)1076-0342(2006)12:2(107)},
  urldate = {2018-12-15}
}

@article{doss-gollinHowUnprecedentedWas2021a,
  title = {How {{Unprecedented Was}} the {{February}} 2021 {{Texas Cold Snap}}?},
  author = {{Doss-Gollin}, James and Farnham, David J. and Lall, Upmanu and Modi, Vijay},
  year = {2021},
  month = jun,
  journal = {Environmental Research Letters},
  issn = {1748-9326},
  doi = {10.1088/1748-9326/ac0278},
  urldate = {2021-05-18},
  abstract = {Winter storm Uri brought severe cold to the southern United States in February 2021, causing a cascading failure of interdependent systems in Texas where infrastructure was not adequately prepared for such cold. In particular, the failure of interconnected energy systems restricted electricity supply just as demand for heating spiked, leaving millions of Texans without heat or electricity, many for several days. This motivates the question: did historical storms suggest that such temperatures were known to occur, and if so with what frequency? We compute a temperature-based proxy for heating demand and use this metric to answer the question ``what would the aggregate demand for heating have been had historic cold snaps occurred with today's population?''. We find that local temperatures and the inferred demand for heating per capita across the region served by the Texas Interconnection were more severe during a storm in December 1989 than during February 2021, and that cold snaps in 1951 and 1983 were nearly as severe. Given anticipated population growth, future storms may lead to even greater infrastructure failures if adaptive investments are not made. Further, electricity system managers should prepare for trends in electrification of heating to drive peak annual loads on the Texas Interconnection during severe winter storms.}
}

@article{doss-gollinImprovingRepresentationClimate2023a,
  title = {Improving the {{Representation}} of {{Climate Risks}} in {{Long-Term Electricity Systems Planning}}: {{A Critical Review}}},
  author = {{Doss-Gollin}, James and Amonkar, Yash and Schmeltzer, Katlyn and Cohan, Daniel},
  year = {2023},
  month = aug,
  journal = {Current Sustainable/Renewable Energy Reports},
  issn = {2196-3010},
  doi = {10.1007/s40518-023-00224-3},
  urldate = {2023-08-16},
  abstract = {Purpose of Review Electricity systems face substantial climate risks which are escalating due to electrification, renewable energy intermittency, population changes, and the intensifying impacts of climate change such as extreme temperatures and weather-induced infrastructure damage. This critical review investigates climate risks to the electricity sector and scrutinizes the methodologies used to represent climate risk in long-term electricity system planning studies. Recent Findings Climate risks to electricity systems are driven by extreme weather, average weather, technology, and other social and technological factors. All are expected to evolve in the future. Future climate risks to electricity systems depend on interactions between each, and thus assessing future climate risks to electricity systems requires exploring a wide range of possible futures. Summary Many studies rely on weather data and socio-economic scenarios that are inadequate to fully characterize climate risks to present and future electricity systems. We advocate for more holistic assessments that incorporate comprehensive weather data, acknowledge dynamic multi-sector interactions, and employ adaptive and robust methodologies.}
}

@article{doss-gollinSubjectiveBayesianFramework2023a,
  title = {A {{Subjective Bayesian Framework}} for {{Synthesizing Deep Uncertainties}} in {{Climate Risk Management}}},
  author = {{Doss-Gollin}, James and Keller, Klaus},
  year = {2023},
  month = jan,
  journal = {Earth's Future},
  volume = {11},
  number = {1},
  issn = {2328-4277},
  doi = {10.1029/2022EF003044},
  urldate = {2022-12-31},
  abstract = {Projections of nonstationary climate risks can vary considerably from one source to another, posing considerable communication and decision-analytical challenges. One such challenge is how to present trade-offs under deep uncertainty in a salient and interpretable manner. Some common approaches include analyzing a small subset of projections or treating all considered projections as equally likely. These approaches can underestimate risks, hide deep uncertainties, and are mostly silent on which assumptions drive decision-relevant outcomes. Here we introduce and demonstrate a transparent Bayesian framework for synthesizing deep uncertainties to inform climate risk management. The first step of this workflow is to generate an ensemble of simulations representing possible futures and analyze them through standard exploratory modeling techniques. Next, a small set of probability distributions representing subjective beliefs about the likelihood of possible futures is used to weight the scenarios. Finally, these weights are used to compute and characterize trade-offs, conduct robustness checks, and reveal implicit assumptions. We demonstrate the framework through a didactic case study analyzing how high to elevate a house to manage coastal flood risks.}
}

@article{ellsbergRiskAmbiguitySavage1961a,
  title = {Risk, {{Ambiguity}}, and the {{Savage Axioms}}},
  author = {Ellsberg, Daniel},
  year = {1961},
  month = nov,
  journal = {The Quarterly Journal of Economics},
  volume = {75},
  number = {4},
  pages = {643--669},
  issn = {0033-5533},
  doi = {10.2307/1884324},
  urldate = {2020-04-10},
  abstract = {Abstract. I. Are there uncertainties that are not risks? 643. --- II. Uncertainties that are not risks, 647. --- III. Why are some uncertainties not risks? --- 656.}
}

@article{fletcherEquityWaterResources2022b,
  title = {Equity in {{Water Resources Planning}}: {{A Path Forward}} for {{Decision Support Modelers}}},
  author = {Fletcher, Sarah and Hadjimichael, Antonia and Quinn, Julianne and Osman, Khalid and Giuliani, Matteo and Gold, David and Figueroa, Anjuli Jain and Gordon, Bethany},
  year = {2022},
  month = jul,
  journal = {Journal of Water Resources Planning and Management},
  volume = {148},
  number = {7},
  pages = {02522005},
  issn = {0733-9496, 1943-5452},
  doi = {10.1061/(ASCE)WR.1943-5452.0001573},
  urldate = {2023-11-25}
}

@article{fletcherLearningClimateChange2019b,
  title = {Learning about {{Climate Change Uncertainty Enables Flexible Water Infrastructure Planning}}},
  author = {Fletcher, Sarah and Lickley, Megan and Strzepek, Kenneth},
  year = {2019},
  month = apr,
  journal = {Nature Communications},
  volume = {10},
  number = {1},
  pages = {1782},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-09677-x},
  urldate = {2019-04-23},
  abstract = {Water resources planning requires infrastructure development consider regional climatic uncertainties. Here the authors introduce a new dynamic planning framework that captures opportunities to learn about climate change over time. By applying it to reservoir planning in Kenya, they show the value of flexible approaches in responding to learning.}
}

@article{frankBoldNewJersey2022a,
  title = {Bold {{New Jersey Shore Flood Rules Could Be Blueprint}} for {{Entire U}}.{{S}}. {{Coast}}},
  author = {Frank, Thomas},
  year = {2022},
  month = aug,
  journal = {Scientific American},
  urldate = {2023-01-11},
  abstract = {Coastal flood zones where development is restricted will be based on future climate change projections, not past floods}
}

@article{garnerUsingDirectPolicy2018b,
  title = {Using {{Direct Policy Search}} to {{Identify Robust Strategies}} in {{Adapting}} to {{Uncertain Sea-Level Rise}} and {{Storm Surge}}},
  author = {Garner, Gregory G. and Keller, Klaus},
  year = {2018},
  month = sep,
  journal = {Environmental Modelling \& Software},
  volume = {107},
  pages = {96--104},
  issn = {1364-8152},
  doi = {10.1016/j.envsoft.2018.05.006},
  urldate = {2019-09-17},
  abstract = {Sea-level rise poses considerable risks to coastal communities, ecosystems, and infrastructure. Decision makers are faced with uncertain sea-level projections when designing a strategy for coastal adaptation. The traditional methods are often silent on tradeoffs as well as the effects of tail-area events and of potential future learning. Here we reformulate a simple sea-level rise adaptation model to address these concerns. We show that Direct Policy Search yields improved solution quality, with respect to Pareto-dominance in the objectives, over the traditional approach under uncertain sea-level rise projections and storm surge. Additionally, the new formulation produces high quality solutions with less computational demands than an intertemporal optimization approach. Our results illustrate the utility of multi-objective adaptive formulations for the example of coastal adaptation and point to wider-ranging application in climate change adaptation decision problems.}
}

@article{gidarisMultipleHazardFragilityRestoration2017a,
  title = {Multiple-{{Hazard Fragility}} and {{Restoration Models}} of {{Highway Bridges}} for {{Regional Risk}} and {{Resilience Assessment}} in the {{United States}}: {{State-of-the-Art Review}}},
  author = {Gidaris, Ioannis and Padgett, Jamie E. and Barbosa, Andre R. and Chen, Suren and Cox, Daniel and Webb, Bret and Cerato, Amy},
  year = {2017},
  month = mar,
  journal = {Journal of Structural Engineering},
  volume = {143},
  number = {3},
  pages = {04016188},
  issn = {1943-541X},
  doi = {10.1061/(ASCE)ST.1943-541X.0001672},
  urldate = {2024-01-22},
  abstract = {AbstractHighway bridges are one of the most vulnerable constituents of transportation networks when exposed to one or more natural hazards, such as earthquakes, hurricanes, tsunamis, and riverine floods. To facilitate and enhance prehazard and posthazard ...}
}

@article{gilliganWickednessManagingComplex2020a,
  title = {Beyond {{Wickedness}}: {{Managing Complex Systems}} and {{Climate Change}}},
  author = {Gilligan, Jonathan M. and Vandenbergh, Michael P.},
  year = {2020},
  journal = {Vanderbilt Law Review},
  volume = {73},
  pages = {1777--1810},
  urldate = {2020-12-23}
}

@article{haasnootDynamicAdaptivePolicy2013a,
  title = {Dynamic Adaptive Policy Pathways: {{A}} Method for Crafting Robust Decisions for a Deeply Uncertain World},
  shorttitle = {Dynamic Adaptive Policy Pathways},
  author = {Haasnoot, Marjolijn and Kwakkel, Jan H. and Walker, Warren E. and {ter Maat}, Judith},
  year = {2013},
  month = apr,
  journal = {Global Environmental Change},
  volume = {23},
  number = {2},
  pages = {485--498},
  issn = {0959-3780},
  doi = {10.1016/j.gloenvcha.2012.12.006},
  urldate = {2024-04-29},
  abstract = {A new paradigm for planning under conditions of deep uncertainty has emerged in the literature. According to this paradigm, a planner should create a strategic vision of the future, commit to short-term actions, and establish a framework to guide future actions. A plan that embodies these ideas allows for its dynamic adaptation over time to meet changing circumstances. We propose a method for decisionmaking under uncertain global and regional changes called `Dynamic Adaptive Policy Pathways'. We base our approach on two complementary approaches for designing adaptive plans: `Adaptive Policymaking' and `Adaptation Pathways'. Adaptive Policymaking is a theoretical approach describing a planning process with different types of actions (e.g. `mitigating actions' and `hedging actions') and signposts to monitor to see if adaptation is needed. In contrast, Adaptation Pathways provides an analytical approach for exploring and sequencing a set of possible actions based on alternative external developments over time. We illustrate the Dynamic Adaptive Policy Pathways approach by producing an adaptive plan for long-term water management of the Rhine Delta in the Netherlands that takes into account the deep uncertainties about the future arising from social, political, technological, economic, and climate changes. The results suggest that it is worthwhile to further test and use the approach.},
  keywords = {Adaptation pathways,Adaptive policies,Policymaking,Rhine delta,Uncertainty,Water management},
  file = {C:\Users\leanh\Zotero\storage\QY4CLNQT\Haasnoot et al. - 2013 - Dynamic adaptive policy pathways A method for cra.pdf}
}

@article{hermanClimateAdaptationControl2020c,
  title = {Climate {{Adaptation}} as a {{Control Problem}}: {{Review}} and {{Perspectives}} on {{Dynamic Water Resources Planning}} under {{Uncertainty}}},
  author = {Herman, Jonathan D. and Quinn, Julianne D. and Steinschneider, Scott and Giuliani, Matteo and Fletcher, Sarah},
  year = {2020},
  month = jan,
  journal = {Water Resources Research},
  pages = {e24389},
  issn = {1944-7973},
  doi = {10.1029/2019wr025502},
  urldate = {2020-01-11},
  abstract = {Climate change introduces substantial uncertainty to water resources planning, and raises the key question: when, or under what conditions, should adaptation occur? A number of recent studies aim to identify policies mapping future observations to actions---in other words, framing climate adaptation as an optimal control problem. This paper uses the control paradigm to review and classify recent dynamic planning studies according to their approaches to uncertainty characterization, policy structure, and solution methods. We propose a set of research gaps and opportunities in this area centered on the challenge of characterizing uncertainty, which prevents the unambiguous application of control methods to this problem. These include: exogenous uncertainty in forcing, model structure, and parameters propagated through a chain of climate and hydrologic models; endogenous uncertainty in human-environmental system dynamics across multiple scales; and sampling uncertainty due to the finite length of historical observations and future projections. Recognizing these challenges, several opportunities exist to improve the use of control methods for climate adaptation, namely: how problem context and understanding of climate processes might assist with uncertainty quantification and experimental design; out-of-sample validation and robustness of optimized adaptation policies; and monitoring and data assimilation, including trend detection, Bayesian inference, and indicator variable selection. We conclude with a summary of recommendations for dynamic water resources planning under climate change through the lens of optimal control.}
}

@article{hermanHowShouldRobustness2015c,
  title = {How {{Should Robustness Be Defined}} for {{Water Systems Planning}} under {{Change}}?},
  author = {Herman, Jonathan D. and Reed, Patrick M. and Zeff, Harrison B. and Characklis, Gregory W.},
  year = {2015},
  month = oct,
  journal = {Journal of Water Resources Planning and Management},
  volume = {141},
  number = {10},
  pages = {04015012},
  doi = {10.1061/(asce)wr.1943-5452.0000509},
  urldate = {2018-12-22}
}

@article{jongmanGlobalExposureRiver2012a,
  title = {Global {{Exposure}} to {{River}} and {{Coastal Flooding}}: {{Long Term Trends}} and {{Changes}}},
  author = {Jongman, Brenden and Ward, Philip J and Aerts, Jeroen C J H},
  year = {2012},
  month = oct,
  journal = {Global Environmental Change},
  volume = {22},
  number = {4},
  pages = {823--835},
  doi = {10.1016/j.gloenvcha.2012.07.004}
}

@article{kasprzykManyObjectiveRobust2013a,
  title = {Many {{Objective Robust Decision Making}} for {{Complex Environmental Systems Undergoing Change}}},
  author = {Kasprzyk, Joseph R. and Nataraj, Shanthi and Reed, Patrick M. and Lempert, Robert J.},
  year = {2013},
  month = apr,
  journal = {Environmental Modelling \& Software},
  volume = {42},
  pages = {55--71},
  issn = {1364-8152},
  doi = {10.1016/j.envsoft.2012.12.007},
  urldate = {2018-12-29},
  abstract = {This paper introduces many objective robust decision making (MORDM). MORDM combines concepts and methods from many objective evolutionary optimization and robust decision making (RDM), along with extensive use of interactive visual analytics, to facilitate the management of complex environmental systems. Many objective evolutionary search is used to generate alternatives for complex planning problems, enabling the discovery of the key tradeoffs among planning objectives. RDM then determines the robustness of planning alternatives to deeply uncertain future conditions and facilitates decision makers' selection of promising candidate solutions. MORDM tests each solution under the ensemble of future extreme states of the world (SOW). Interactive visual analytics are used to explore whether solutions of interest are robust to a wide range of plausible future conditions (i.e., assessment of their Pareto satisficing behavior in alternative SOW). Scenario discovery methods that use statistical data mining algorithms are then used to identify what assumptions and system conditions strongly influence the cost-effectiveness, efficiency, and reliability of the robust alternatives. The framework is demonstrated using a case study that examines a single city's water supply in the Lower Rio Grande Valley (LRGV) in Texas, USA. Results suggest that including robustness as a decision criterion can dramatically change the formulation of complex environmental management problems as well as the negotiated selection of candidate alternatives to implement. MORDM also allows decision makers to characterize the most important vulnerabilities for their systems, which should be the focus of ex post monitoring and identification of triggers for adaptive management.}
}

@article{kellerClimateRiskManagement2021b,
  title = {Climate {{Risk Management}}},
  author = {Keller, Klaus and Helgeson, Casey and Srikrishnan, Vivek},
  year = {2021},
  journal = {Annual Review of Earth and Planetary Sciences},
  volume = {49},
  number = {1},
  pages = {95--116},
  issn = {0084-6597},
  doi = {10.1146/annurev-earth-080320-055847}
}

@article{koppEvolvingUnderstandingAntarctic2017a,
  title = {Evolving {{Understanding}} of {{Antarctic Ice-Sheet Physics}} and {{Ambiguity}} in {{Probabilistic Sea-Level Projections}}},
  author = {Kopp, Robert E. and DeConto, Robert M. and Bader, Daniel A. and Hay, Carling C. and Horton, Radley M. and Kulp, Scott and Oppenheimer, Michael and Pollard, David and Strauss, Benjamin H.},
  year = {2017},
  journal = {Earth's Future},
  volume = {5},
  number = {12},
  pages = {1217--1233},
  issn = {2328-4277},
  doi = {10.1002/2017ef000663},
  urldate = {2020-02-16},
  abstract = {Mechanisms such as ice-shelf hydrofracturing and ice-cliff collapse may rapidly increase discharge from marine-based ice sheets. Here, we link a probabilistic framework for sea-level projections to a small ensemble of Antarctic ice-sheet (AIS) simulations incorporating these physical processes to explore their influence on global-mean sea-level (GMSL) and relative sea-level (RSL). We compare the new projections to past results using expert assessment and structured expert elicitation about AIS changes. Under high greenhouse gas emissions (Representative Concentration Pathway [RCP] 8.5), median projected 21st century GMSL rise increases from 79 to 146 cm. Without protective measures, revised median RSL projections would by 2100 submerge land currently home to 153 million people, an increase of 44 million. The use of a physical model, rather than simple parameterizations assuming constant acceleration of ice loss, increases forcing sensitivity: overlap between the central 90\% of simulations for 2100 for RCP 8.5 (93--243 cm) and RCP 2.6 (26--98 cm) is minimal. By 2300, the gap between median GMSL estimates for RCP 8.5 and RCP 2.6 reaches {\textbackslash}textgreater10 m, with median RSL projections for RCP 8.5 jeopardizing land now occupied by 950 million people (versus 167 million for RCP 2.6). The minimal correlation between the contribution of AIS to GMSL by 2050 and that in 2100 and beyond implies current sea-level observations cannot exclude future extreme outcomes. The sensitivity of post-2050 projections to deeply uncertain physics highlights the need for robust decision and adaptive management frameworks.}
}

@article{koppProbabilistic21st22nd2014a,
  title = {Probabilistic 21st and 22nd {{Century Sea-Level Projections}} at a {{Global Network}} of {{Tide-Gauge Sites}}},
  author = {Kopp, Robert E. and Horton, Radley M. and Little, Christopher M. and Mitrovica, Jerry X. and Oppenheimer, Michael and Rasmussen, D. J. and Strauss, Benjamin H. and Tebaldi, Claudia},
  year = {2014},
  journal = {Earth's Future},
  volume = {2},
  number = {8},
  pages = {383--406},
  issn = {2328-4277},
  doi = {10.1002/2014ef000239},
  urldate = {2020-02-08},
  abstract = {Sea-level rise due to both climate change and non-climatic factors threatens coastal settlements, infrastructure, and ecosystems. Projections of mean global sea-level (GSL) rise provide insufficient information to plan adaptive responses; local decisions require local projections that accommodate different risk tolerances and time frames and that can be linked to storm surge projections. Here we present a global set of local sea-level (LSL) projections to inform decisions on timescales ranging from the coming decades through the 22nd century. We provide complete probability distributions, informed by a combination of expert community assessment, expert elicitation, and process modeling. Between the years 2000 and 2100, we project a very likely (90\% probability) GSL rise of 0.5--1.2 m under representative concentration pathway (RCP) 8.5, 0.4--0.9 m under RCP 4.5, and 0.3--0.8 m under RCP 2.6. Site-to-site differences in LSL projections are due to varying non-climatic background uplift or subsidence, oceanographic effects, and spatially variable responses of the geoid and the lithosphere to shrinking land ice. The Antarctic ice sheet (AIS) constitutes a growing share of variance in GSL and LSL projections. In the global average and at many locations, it is the dominant source of variance in late 21st century projections, though at some sites oceanographic processes contribute the largest share throughout the century. LSL rise dramatically reshapes flood risk, greatly increasing the expected number of ``1-in-10'' and ``1-in-100'' year events.}
}

@incollection{lallChapterWater2018a,
  title = {Chapter 3: {{Water}}},
  booktitle = {Impacts, {{Risks}}, and {{Adaptation}} in the {{United States}}: {{The Fourth National Climate Assessment}}, {{Volume II}}},
  author = {Lall, Upmanu and Johnson, Thomas and Colohan, Peter and Aghakouchak, Amir and Arumugam, Sankar and Brown, Casey and Mccabe, Gregory J. and Pulwarty, Roger S.},
  year = {2018},
  publisher = {U.S. Global Change Research Program},
  address = {Washington, D.C.},
  doi = {10.7930/NCA4.2018.CH3},
  urldate = {2022-10-30}
}

@article{lamontagneRobustAbatementPathways2019a,
  title = {Robust {{Abatement Pathways}} to {{Tolerable Climate Futures Require Immediate Global Action}}},
  author = {Lamontagne, J. R. and Reed, P. M. and Marangoni, G. and Keller, K. and Garner, G. G.},
  year = {2019},
  month = apr,
  journal = {Nature Climate Change},
  volume = {9},
  number = {4},
  pages = {290--294},
  issn = {1758-6798},
  doi = {10.1038/s41558-019-0426-8},
  urldate = {2019-09-12},
  abstract = {Uncertainties are often cited as a reason for mitigation inaction. Here, millions of scenarios are evaluated to assess the relative importance of human--earth system uncertainties and policy variables. The growth rate of global abatement is found to be the primary driver of long-term warming.}
}

@article{leeImpactNeglectingClimate2022a,
  title = {The {{Impact}} of {{Neglecting Climate Change}} and {{Variability}} on {{ERCOT}}'s {{Forecasts}} of {{Electricity Demand}} in {{Texas}}},
  author = {Lee, Jangho and Dessler, Andrew E.},
  year = {2022},
  month = apr,
  journal = {Weather, Climate, and Society},
  volume = {14},
  number = {2},
  pages = {499--505},
  issn = {1948-8327, 1948-8335},
  doi = {10.1175/WCAS-D-21-0140.1},
  urldate = {2022-07-03},
  abstract = {Abstract The Electric Reliability Council of Texas (ERCOT) manages the electric power across most of Texas. They make short-term assessments of electricity demand on the basis of historical weather over the last two decades, thereby ignoring the effects of climate change and the possibility of weather variability outside the recent historical range. In this paper, we develop an empirical method to predict the impact of weather on energy demand. We use that with a large ensemble of climate model runs to construct a probability distribution of power demand on the ERCOT grid for summer and winter 2021. We find that the most severe weather events will use 100\% of available power---if anything goes wrong, as it did during the 2021 winter, there will not be sufficient available power. More quantitatively, we estimate a 5\% chance that maximum power demand would be within 4.3 and 7.9 GW of ERCOT's estimate of best-case available resources during summer and winter 2021, respectively, and a 20\% chance it would be within 7.1 and 17 GW. The shortage of power on the ERCOT grid is partially hidden by the fact that ERCOTs seasonal assessments, which are based entirely on historical weather, are too low. Prior to the 2021 winter blackout, ERCOT forecast an extreme peak load of 67 GW. In reality, we estimate hourly peak demand was 82 GW, 22\% above ERCOT's most extreme forecast and about equal to the best-case available power. Given the high stakes, ERCOT should develop probabilistic estimates using modern scientific tools to predict the range of power demand more accurately.}
}

@article{lempertRobustStrategiesAbating2000c,
  title = {Robust {{Strategies}} for {{Abating Climate Change}}},
  author = {Lempert, Robert J. and Schlesinger, Michael E.},
  year = {2000},
  month = jun,
  journal = {Climatic Change},
  volume = {45},
  number = {3},
  pages = {387--401},
  issn = {01650009},
  doi = {10.1023/A:1005698407365},
  urldate = {2022-09-28},
  abstract = {The need for climate-change decisionmakers to craft strategies that are robust in the face of an unpredictable future is addressed. The climate-change policymaking community could do policymakers a great service by examining signposts that might provide a better basis for building near-term climate-change policies.}
}

@book{loucksWaterResourceSystems2017a,
  title = {Water {{Resource Systems Planning}} and {{Management}}: {{An Introduction}} to {{Methods}}, {{Models}}, and {{Applications}}},
  author = {Loucks, Daniel P.},
  year = {2017},
  publisher = {Imprint: Springer},
  address = {Cham},
  isbn = {978-3-319-44234-1}
}

@article{mcphailRobustnessMetricsHow2019a,
  title = {Robustness {{Metrics}}: {{How Are They Calculated}}, {{When Should They Be Used}} and {{Why Do They Give Different Results}}?},
  author = {McPhail, C. and Maier, H. R. and Kwakkel, J. H. and Giuliani, M. and Castelletti, A. and Westra, S.},
  year = {2019},
  month = apr,
  journal = {Earth's Future},
  pages = {169--191},
  issn = {2328-4277},
  doi = {10.1002/2017ef000649},
  urldate = {2019-11-20},
  abstract = {Abstract Robustness is being used increasingly for decision analysis in relation to deep uncertainty and many metrics have been proposed for its quantification. Recent studies have shown that the application of different robustness metrics can result in different rankings of decision alternatives, but there has been little discussion of what potential causes for this might be. To shed some light on this issue, we present a unifying framework for the calculation of robustness metrics, which assists with understanding how robustness metrics work, when they should be used, and why they sometimes disagree. The framework categorizes the suitability of metrics to a decision-maker based on (1) the decision-context (i.e., the suitability of using absolute performance or regret), (2) the decision-maker's preferred level of risk aversion, and (3) the decision-maker's preference toward maximizing performance, minimizing variance, or some higher-order moment. This article also introduces a conceptual framework describing when relative robustness values of decision alternatives obtained using different metrics are likely to agree and disagree. This is used as a measure of how ?stable? the ranking of decision alternatives is when determined using different robustness metrics. The framework is tested on three case studies, including water supply augmentation in Adelaide, Australia, the operation of a multipurpose regulated lake in Italy, and flood protection for a hypothetical river based on a reach of the river Rhine in the Netherlands. The proposed conceptual framework is confirmed by the case study results, providing insight into the reasons for disagreements between rankings obtained using different robustness metrics.}
}

@article{oddoDeepUncertaintiesSeaLevel2017a,
  title = {Deep {{Uncertainties}} in {{Sea-Level Rise}} and {{Storm Surge Projections}}: {{Implications}} for {{Coastal Flood Risk Management}}},
  author = {Oddo, Perry C. and Lee, Ben S. and Garner, Gregory G. and Srikrishnan, Vivek and Reed, Patrick M. and Forest, Chris E. and Keller, Klaus},
  year = {2017},
  journal = {Risk Analysis},
  volume = {0},
  number = {0},
  issn = {1539-6924},
  doi = {10/ghkp82},
  urldate = {2019-09-11},
  abstract = {Sea levels are rising in many areas around the world, posing risks to coastal communities and infrastructures. Strategies for managing these flood risks present decision challenges that require a combination of geophysical, economic, and infrastructure models. Previous studies have broken important new ground on the considerable tensions between the costs of upgrading infrastructure and the damages that could result from extreme flood events. However, many risk-based adaptation strategies remain silent on certain potentially important uncertainties, as well as the tradeoffs between competing objectives. Here, we implement and improve on a classic decision-analytical model (Van Dantzig 1956) to: (i) capture tradeoffs across conflicting stakeholder objectives, (ii) demonstrate the consequences of structural uncertainties in the sea-level rise and storm surge models, and (iii) identify the parametric uncertainties that most strongly influence each objective using global sensitivity analysis. We find that the flood adaptation model produces potentially myopic solutions when formulated using traditional mean-centric decision theory. Moving from a single-objective problem formulation to one with multiobjective tradeoffs dramatically expands the decision space, and highlights the need for compromise solutions to address stakeholder preferences. We find deep structural uncertainties that have large effects on the model outcome, with the storm surge parameters accounting for the greatest impacts. Global sensitivity analysis effectively identifies important parameter interactions that local methods overlook, and that could have critical implications for flood adaptation strategies.}
}

@article{oreskesVerificationValidationConfirmation1994b,
  title = {Verification, {{Validation}}, and {{Confirmation}} of {{Numerical Models}} in the {{Earth Sciences}}},
  author = {Oreskes, Naomi and {Shrader-Frechette}, Kristin and Belitz, Kenneth},
  year = {1994},
  month = feb,
  journal = {Science},
  doi = {10.1126/science.263.5147.641},
  urldate = {2021-09-02},
  abstract = {Verification and validation of numerical models of natural systems is impossible. This is because natural systems are never closed and because model results are always nonunique. Models can be confirmed by the demonstration of agreement between ...}
}

@techreport{pblnetherlandsenvironmentalassessmentagencyGeographyFutureWater2019a,
  title = {The {{Geography}} of {{Future Water Challenges}}},
  author = {{PBL Netherlands Environmental Assessment Agency}},
  year = {2019},
  address = {The Hague},
  institution = {PBL Netherlands Environmental Assessment Agency}
}

@misc{pollackTransparencyUnderlyingValues2023a,
  title = {Transparency on {{Underlying Values Is Needed}} for {{Useful Equity Measurements}}},
  author = {Pollack, Adam and Helgeson, Casey and Kousky, Carolyn and Keller, Klaus},
  year = {2023},
  month = sep,
  doi = {10.31219/osf.io/kvyxr},
  urldate = {2023-11-22},
  abstract = {Decision-makers increasingly invoke equity to motivate, design, implement, and evaluate strategies for managing flood risks. But there is no objective definition of equity. This pluralistic setting calls for transparency about underlying values, but this practice is uncommon. Here, we review how equity is measured by surveying peer-reviewed publications that explicitly state an interest in equity in the context of flood-risk management. We develop a simple taxonomy for how transparent measurements can be defined. We map reviewed measurements to this taxonomy. Finally, we offer guidance on how the pursuit of a clear and consistent quantitative evidence base about equity can become more widespread in flood-risk research and beyond.},
  howpublished = {https://osf.io/kvyxr/}
}

@article{quinnDirectPolicySearch2017b,
  title = {Direct {{Policy Search}} for {{Robust Multi-Objective Management}} of {{Deeply Uncertain Socio-Ecological Tipping Points}}},
  author = {Quinn, Julianne D. and Reed, Patrick M. and Keller, Klaus},
  year = {2017},
  month = jun,
  journal = {Environmental Modelling \& Software},
  volume = {92},
  pages = {125--141},
  issn = {1364-8152},
  doi = {10.1016/j.envsoft.2017.02.017},
  urldate = {2019-09-27},
  abstract = {Managing socio-ecological systems is a challenge wrought by competing societal objectives, deep uncertainties, and potentially irreversible tipping points. A classic, didactic example is the shallow lake problem in which a hypothetical town situated on a lake must develop pollution control strategies to maximize its economic benefits while minimizing the probability of the lake crossing a critical phosphorus (P) threshold, above which it irreversibly transitions into a eutrophic state. Here, we explore the use of direct policy search (DPS) to design robust pollution control rules for the town that account for deeply uncertain system characteristics and conflicting objectives. The closed loop control formulation of DPS improves the quality and robustness of key management tradeoffs, while dramatically reducing the computational complexity of solving the multi-objective pollution control problem relative to open loop control strategies. These insights suggest DPS is a promising tool for managing socio-ecological systems with deeply uncertain tipping points.}
}

@article{reedEvolutionaryMultiobjectiveOptimization2013a,
  title = {Evolutionary {{Multiobjective Optimization}} in {{Water Resources}}: {{The Past}}, {{Present}}, and {{Future}}},
  author = {Reed, P. M. and Hadka, D. and Herman, J. D. and Kasprzyk, J. R. and Kollat, J. B.},
  year = {2013},
  month = jan,
  journal = {Advances in Water Resources},
  series = {35th {{Year Anniversary Issue}}},
  volume = {51},
  pages = {438--456},
  issn = {0309-1708},
  doi = {10.1016/j.advwatres.2012.01.005},
  urldate = {2019-03-12},
  abstract = {This study contributes a rigorous diagnostic assessment of state-of-the-art multiobjective evolutionary algorithms (MOEAs) and highlights key advances that the water resources field can exploit to better discover the critical tradeoffs constraining our systems. This study provides the most comprehensive diagnostic assessment of MOEAs for water resources to date, exploiting more than 100,000 MOEA runs and trillions of design evaluations. The diagnostic assessment measures the effectiveness, efficiency, reliability, and controllability of ten benchmark MOEAs for a representative suite of water resources applications addressing rainfall--runoff calibration, long-term groundwater monitoring (LTM), and risk-based water supply portfolio planning. The suite of problems encompasses a range of challenging problem properties including (1) many-objective formulations with four or more objectives, (2) multi-modality (or false optima), (3) nonlinearity, (4) discreteness, (5) severe constraints, (6) stochastic objectives, and (7) non-separability (also called epistasis). The applications are representative of the dominant problem classes that have shaped the history of MOEAs in water resources and that will be dominant foci in the future. Recommendations are given for the new algorithms that should serve as the benchmarks for innovations in the water resources literature. The future of MOEAs in water resources needs to emphasize self-adaptive search, new technologies for visualizing tradeoffs, and the next generation of computing technologies.}
}

@article{reedMultisectorDynamicsAdvancing2022b,
  title = {Multisector {{Dynamics}}: {{Advancing}} the {{Science}} of {{Complex Adaptive Human-Earth Systems}}},
  author = {Reed, Patrick M. and Hadjimichael, Antonia and Moss, Richard H. and Brelsford, Christa and Burleyson, Casey D. and Cohen, Stuart and Dyreson, Ana and Gold, David F. and Gupta, Rohini S. and Keller, Klaus and Konar, Megan and Monier, Erwan and Morris, Jennifer and Srikrishnan, Vivek and Voisin, Nathalie and Yoon, Jim},
  year = {2022},
  journal = {Earth's Future},
  volume = {10},
  number = {3},
  pages = {e2021EF002621},
  issn = {2328-4277},
  doi = {10.1029/2021EF002621},
  urldate = {2022-03-03},
  abstract = {The field of MultiSector Dynamics (MSD) explores the dynamics and co-evolutionary pathways of human and Earth systems with a focus on critical goods, services, and amenities delivered to people through interdependent sectors. This commentary lays out core definitions and concepts, identifies MSD science questions in the context of the current state of knowledge, and describes ongoing activities to expand capacities for open science, leverage revolutions in data and computing, and grow and diversify the MSD workforce. Central to our vision is the ambition of advancing the next generation of complex adaptive human-Earth systems science to better address interconnected risks, increase resilience, and improve sustainability. This will require convergent research and the integration of ideas and methods from multiple disciplines. Understanding the tradeoffs, synergies, and complexities that exist in coupled human-Earth systems is particularly important in the context of energy transitions and increased future shocks.}
}

@article{satijaBoomtownFloodTown2016a,
  title = {Boomtown, {{Flood Town}}},
  author = {Satija, Nina and Collier, Kiah and Shaw, Al},
  year = {2016},
  month = dec,
  journal = {ProPublica},
  urldate = {2021-05-31},
  abstract = {Climate change will bring more frequent and fierce rainstorms to cities like Houston. But unchecked development remains a priority in the famously un-zoned city, creating short-term economic gains for some while increasing flood risks for everyone.}
}

@book{savageFoundationsStatistics1954a,
  title = {Foundations of {{Statistics}}.},
  author = {Savage, L.J.},
  year = {1954},
  publisher = {Wiley},
  address = {New York}
}

@article{schneiderCanWeEstimate2002b,
  title = {Can {{We Estimate}} the {{Likelihood}} of {{Climatic Changes}} at 2100?},
  author = {Schneider, Stephen H.},
  year = {2002},
  month = mar,
  journal = {Climatic Change},
  volume = {52},
  number = {4},
  pages = {441--451},
  issn = {01650009},
  doi = {http://dx.doi.org/10.1023/A:1014276210717},
  urldate = {2021-10-26},
  abstract = {Schneider points out some of the consequences of the deliberate choice not to discuss the possibilities of CO2 emissions and how that can--and has--led to confusion on the part of the media and policy makers over the likelihood of potential dangerous anthropogenic climate change in the next century.}
}

@article{schwetschenauOptimizingScaleDecentralized2023b,
  title = {Optimizing {{Scale}} for {{Decentralized Wastewater Treatment}}: {{A Tool}} to {{Address Failing Wastewater Infrastructure}} in the {{United States}}},
  author = {Schwetschenau, Sara E. and Kovankaya, Yunus and Elliott, Mark A. and Allaire, Maura and White, Kevin D. and Lall, Upmanu},
  year = {2023},
  month = jan,
  journal = {ACS ES\&T Engineering},
  volume = {3},
  number = {1},
  pages = {1--14},
  doi = {10.1021/acsestengg.2c00188},
  urldate = {2023-09-19},
  abstract = {Wastewater systems (sewered or on-site septic tanks) are failing across the U.S. Economically disadvantaged populations, communities of color, tribal lands, and rural/peri-urban areas are especially vulnerable. Efficient deployment of public and private capital to assure appropriate service levels and affordability is a critical need. We present a modeling framework to identify economically optimal wastewater network layout and component sizes. Six system configurations are considered, which include gravity versus pressurized collection system flow and treatment of septic effluent versus raw wastewater. A case study for Uniontown, Alabama-a community that has been in national news for the failure of their wastewater infrastructure-is presented. We find that a decentralized network that separates and stores solids on-site, prior to conveyance to a cluster-scale treatment site, has a fraction of the capital and operating cost of a centralized system that is currently proposed. Broader implications are discussed.}
}

@incollection{seneviratneWeatherClimateExtreme2021a,
  title = {Weather and {{Climate Extreme Events}} in a {{Changing Climate}}},
  booktitle = {Climate {{Change}} 2021: {{The Physical Science Basis}}. {{Contribution}} of {{Working Group I}} to the {{Sixth Assessment Report}} of the {{Intergovernmental Panel}} on {{Climate Change}}},
  author = {Seneviratne, S.I. and Zhang, X. and Adnan, M. and Badi, W. and Dereczynski, C. and Di Luca, A. and Ghosh, S. and Iskandar, I. and Kossin, J. and Lewis, S. and Otto, F. and Pinto, I. and Satoh, M. and {Vicente-Serrano}, S.M. and Wehner, M. and Zhou, B.},
  editor = {{Masson-Delmotte}, V. and Zhai, P. and Pirani, A. and Connors, S. L. and P{\'e}an, C. and Berger, S. and Caud, N. and Chen, Y. and Goldfarb, L. and Gomis, M. I. and Huang, M. and Leitzell, K. and Lonnoy, E. and Matthews, J. B. R. and Maycock, T. K. and Waterfield, T. and Yelek{\c c}i, O. and Yu, R. and Zhou, B.},
  year = {2021},
  publisher = {Cambridge University Press},
  address = {Cambridge, UK and New York, NY, USA},
  doi = {10.1017/9781009157896.013}
}

@article{smithMultiobjectiveOptimizationPareto2022a,
  title = {Multiobjective {{Optimization}} and {{Pareto Front Visualization Techniques Applied}} to {{Normal Conducting Rf Accelerating Structures}}},
  author = {Smith, S. and Southerby, M. and Setiniyaz, S. and Apsimon, R. and Burt, G.},
  year = {2022},
  month = jun,
  journal = {Physical Review Accelerators and Beams},
  volume = {25},
  number = {6},
  pages = {062002},
  doi = {10.1103/PhysRevAccelBeams.25.062002},
  urldate = {2024-02-26},
  abstract = {There has been a renewed interest in applying multiobjective (MO) optimization methods to a number of problems in the physical sciences, including to rf structure design. The results of these optimizations generate large datasets, which makes visualizing the data and selecting individual solutions difficult. Using the generated results, Pareto fronts can be found giving the trade-off between different objectives, allowing one to utilize this key information in design decisions. Although various visualization techniques exist, it can be difficult to know which technique is appropriate and how to apply them successfully to the problem at hand. First, we present the setup and execution of MO optimizations of one standing wave and one traveling wave accelerating cavity, including constraint handling and an algorithm comparison. In order to understand the generated Pareto frontiers, we discuss several visualization techniques, applying them to the problem, and give the benefits and drawbacks of each. We found that the best techniques involve clustering the resulting data first to narrow down the possible choices and then using multidimensional visualization methods such as parallel coordinate plots and decision maps to view the clustered results and select individual solutions. Finally, we give some examples of the application of these methods and the cavities selected based on arbitrary design requirements.}
}

@article{sommerUnexpectedItemBlocking2022b,
  title = {An {{Unexpected Item Is Blocking Cities}}' {{Climate Change Prep}}: {{Obsolete Rainfall Records}}},
  author = {Sommer, Lauren},
  year = {2022},
  month = feb,
  journal = {NPR},
  urldate = {2024-01-05},
  abstract = {Cities are experiencing heavier storms and flooding as the climate gets hotter. But due to outdated rainfall records, many are still building infrastructure for the climate of the past.}
}

@article{steinschneiderExpandedDecisionScalingFramework2015a,
  title = {Expanded {{Decision-Scaling Framework}} to {{Select Robust Long-Term Water-System Plans}} under {{Hydroclimatic Uncertainties}}},
  author = {Steinschneider, Scott and McCrary, Rachel and Wi, Sungwook and Mulligan, Kevin and Mearns, Linda O and Brown, Casey M},
  year = {2015},
  month = nov,
  journal = {Journal of Water Resources Planning and Management},
  volume = {141},
  number = {11},
  doi = {10.1061/(asce)wr.1943-5452.0000536}
}

@book{suttonReinforcementLearningIntroduction2018a,
  title = {Reinforcement {{Learning}}: {{An Introduction}}},
  author = {Sutton, Richard S and Barto, Andrew G},
  year = {2018},
  edition = {Second Edition},
  publisher = {MIT Press},
  address = {Cambridge, Massachusetts and London, England},
  isbn = {0-262-03924-9}
}

@techreport{sweetGlobalRegionalSea2022a,
  type = {{{NOAA Technical Report}}},
  title = {Global and {{Regional Sea Level Rise Scenarios}} for the {{United States}}},
  author = {Sweet, W.V. and Hamlington, B.D. and Kopp, R.E. and Weaver, C.P. and Barnard, P.L. and Bekaert, D. and Brooks, W. and Craghan, M. and Dusek, G.},
  year = {2022},
  number = {NOS 01},
  pages = {111},
  address = {Silver Spring, MD},
  institution = {{National Oceanic and Atmospheric Administration, National Ocean Service}}
}

@article{tedescoExposureRealEstate2020a,
  title = {Exposure of {{Real Estate Properties}} to the 2018 {{Hurricane Florence Flooding}}},
  author = {Tedesco, Marco and McAlpine, Steven and Porter, Jeremy R.},
  year = {2020},
  month = apr,
  journal = {Natural Hazards and Earth System Sciences},
  volume = {20},
  number = {3},
  pages = {907--920},
  issn = {1561-8633},
  doi = {10.5194/nhess-20-907-2020},
  urldate = {2020-04-11},
  abstract = {Quantifying the potential exposure of property to damages associated with storm surges, extreme weather and hurricanes is fundamental to developing frameworks that can be used to conceive and implement mitigation plans as well as support urban development that accounts for such events. In this study, we aim at quantifying the total value and area of properties exposed to the flooding associated with Hurricane Florence that occurred in September 2018. To this aim, we implement an approach for the identification of affected areas by generating a map of the maximum flood extent obtained from a combination of the flood extent produced by the Federal Emergency Management Agency's (FEMA's) water marks with those obtained from spaceborne radar remote-sensing data. The use of radar in the creation of the flood extent allows for those properties commonly missed by FEMA's interpolation methods, especially from pluvial or non-fluvial sources, and can be used in more accurately estimating the exposure and market value of properties to event-specific flooding. Lastly, we study and quantify how the urban development over the past decades in the regions flooded by Hurricane Florence might have impacted the exposure of properties to present-day storms and floods. This approach is conceptually similar to what experts are addressing as the ``expanding bull's eye effect'', in which ``targets'' of geophysical hazards, such as people and their built environments, enlarge as populations grow and spread. Our results indicate that the total value of property exposed to flooding during Hurricane Florence was USD\&thinsp;52 billion (in 2018 USD), with this value increasing from USD\&thinsp;{$\sim$}10 billion at the beginning of the past century to the final amount based on the expansion of the number of properties exposed. We also found that, despite the decrease in the number of properties built during the decade before Florence, much of the new construction was in proximity to permanent water bodies, hence increasing exposure to flooding. Ultimately, the results of this paper provide a new tool for shedding light on the relationships between urban development in coastal areas and the flooding of those areas, which is estimated to increase in view of projected increasing sea level rise, storm surges and the strength of storms.}
}

@article{thomsonSystemicFinancialRisk2023b,
  title = {Systemic {{Financial Risk Arising From Residential Flood Losses}}},
  author = {Thomson, Hope and Zeff, Harrison B. and Kleiman, Rachel and Sebastian, Antonia and Characklis, Gregory W.},
  year = {2023},
  journal = {Earth's Future},
  volume = {11},
  number = {4},
  pages = {e2022EF003206},
  issn = {2328-4277},
  doi = {10.1029/2022EF003206},
  urldate = {2023-07-07},
  abstract = {Direct damage from flooding at residential properties has typically been categorized as insured, with liabilities accruing to insurers, or uninsured, with costs accruing to property owners. However, residential flooding can also expose lenders and local governments to financial risk, though the distribution of this risk is not well understood. Flood losses are not limited to direct damages, but also include indirect effects such as decreases in property values, which can be substantial, though are rarely well quantified. The combination of direct damage and property value decrease influences rates of mortgage default and property abandonment in the wake of a flood, creating financial risk. In this research, property-level data on sales, mortgages, and insurance claims are used in combination with machine learning techniques and geostatistical methods to provide estimates of flood losses that are then utilized to evaluate the risk of default and abandonment in eastern North Carolina following Hurricane Florence (2018). Within the study area, Hurricane Florence generated {\textbackslash}textbackslashtextbackslash 366M in observed insured damages and an estimated {\textbackslash}textbackslashtextbackslash 1.77B in combined uninsured damages and property value decreases. Property owners, lenders, and local governments were exposed to an additional \$562M in potential losses due to increased rates of default and abandonment. Areas with lower pre-flood property values were exposed to greater risk than areas with higher valued properties. Results suggest more highly resolved estimates of a flooding event's systemic financial risk may be useful in developing improved flood resilience strategies.}
}

@book{tyeImpactsFutureWeather2021a,
  title = {Impacts of {{Future Weather}} and {{Climate Extremes}} on {{United States Infrastructure}}: {{Assessing}} and {{Prioritizing Adaptation Actions}}},
  author = {Tye, Mari R. and Giovannettone, Jason P.},
  year = {2021},
  month = oct,
  publisher = {American Society of Civil Engineers},
  address = {Reston, VA},
  doi = {10.1061/9780784415863},
  urldate = {2022-11-14},
  isbn = {978-0-7844-1586-3 978-0-7844-8372-5}
}

@article{vanberchumEvaluationFloodRisk2019b,
  title = {Evaluation of {{Flood Risk Reduction Strategies}} through {{Combinations}} of {{Interventions}}},
  author = {{van Berchum}, Erik C. and Mobley, William and Jonkman, Sebastiaan N. and Timmermans, Jos S. and Kwakkel, Jan H. and Brody, Samuel D.},
  year = {2019},
  journal = {Journal of Flood Risk Management},
  volume = {12},
  number = {S2},
  pages = {e12506},
  issn = {1753-318X},
  doi = {10.1111/jfr3.12506},
  urldate = {2023-01-17},
  abstract = {Large, complex coastal regions often require a combination of interventions to lower the risk of flooding to an acceptable level. In practice, a limited number of strategies are considered and interdependencies between interventions are often simplified. This paper presents the Multiple Lines of Defence Optimization System (MODOS)-model. This quick, probabilistic model simulates and evaluates the impact of many flood risk reduction strategies while accounting for interdependencies amongst measures. The simulation includes hydraulic calculations, damage calculations, and the effects of measures for various return periods. The application and potential of this model is shown with a conceptual and simplified case study, based on the Houston-Galveston Bay area. The analyses demonstrate how the MODOS-model identifies trade-offs within the system and shows how flood risk, cost, and impact respond to flood management decisions. This improved understanding of the impact of design and planning choices can benefit the discussions in finding the optimal flood risk reduction strategy for coastal regions.}
}

@article{vandantzigEconomicDecisionProblems1956a,
  title = {Economic {{Decision Problems}} for {{Flood Prevention}}},
  author = {{van Dantzig}, D.},
  year = {1956},
  journal = {Econometrica},
  volume = {24},
  number = {3},
  pages = {276--287},
  issn = {0012-9682},
  doi = {10.2307/1911632},
  urldate = {2019-09-12}
}

@article{wardHowAreFlood2011a,
  title = {How {{Are Flood Risk Estimates Affected}} by the {{Choice}} of {{Return-Periods}}?},
  author = {Ward, P. J. and {de Moel}, H. and Aerts, J. C. J. H.},
  year = {2011},
  month = dec,
  journal = {Natural Hazards and Earth System Sciences},
  volume = {11},
  number = {12},
  pages = {3181--3195},
  issn = {1561-8633},
  doi = {10.5194/nhess-11-3181-2011},
  urldate = {2024-01-20},
  abstract = {Flood management is more and more adopting a risk based approach, whereby flood risk is the product of the probability and consequences of flooding. One of the most common approaches in flood risk assessment is to estimate the damage that would occur for floods of several exceedance probabilities (or return periods), to plot these on an exceedance probability-loss curve (risk curve) and to estimate risk as the area under the curve. However, there is little insight into how the selection of the return-periods (which ones and how many) used to calculate risk actually affects the final risk calculation. To gain such insights, we developed and validated an inundation model capable of rapidly simulating inundation extent and depth, and dynamically coupled this to an existing damage model. The method was applied to a section of the River Meuse in the southeast of the Netherlands. Firstly, we estimated risk based on a risk curve using yearly return periods from 2 to 10 000 yr ({\texteuro} 34 million p.a.). We found that the overall risk is greatly affected by the number of return periods used to construct the risk curve, with over-estimations of annual risk between 33\% and 100\% when only three return periods are used. In addition, binary assumptions on dike failure can have a large effect (a factor two difference) on risk estimates. Also, the minimum and maximum return period considered in the curve affects the risk estimate considerably. The results suggest that more research is needed to develop relatively simple inundation models that can be used to produce large numbers of inundation maps, complementary to more complex 2-D--3-D hydrodynamic models. It also suggests that research into flood risk could benefit by paying more attention to the damage caused by relatively high probability floods.}
}

@article{weitzmanReviewSternReview2007a,
  title = {A {{Review}} of the {{Stern Review}} on the {{Economics}} of {{Climate Change}}},
  author = {Weitzman, Martin L.},
  year = {2007},
  month = sep,
  journal = {Journal of Economic Literature},
  volume = {45},
  number = {3},
  pages = {703--724},
  issn = {0022-0515},
  doi = {10.1257/jel.45.3.703},
  urldate = {2019-09-21}
}

@article{wingNewInsightsUS2020b,
  title = {New {{Insights}} into {{US Flood Vulnerability Revealed}} from {{Flood Insurance Big Data}}},
  author = {Wing, Oliver E. J. and Pinter, Nicholas and Bates, Paul D. and Kousky, Carolyn},
  year = {2020},
  month = mar,
  journal = {Nature Communications},
  volume = {11},
  number = {1},
  pages = {1444},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-15264-2},
  urldate = {2021-02-16},
  abstract = {Improvements in modelling power and input data have vastly improved the precision of physical flood models, but translation into economic outputs requires depth--damage functions that are inadequately verified. In particular, flood damage is widely assumed to increase monotonically with water depth. Here, we assess flood vulnerability in the US using {\textbackslash}textgreater2 million claims from the National Flood Insurance Program (NFIP). NFIP claims data are messy, but the size of the dataset provides powerful empirical tests of damage patterns and modelling approaches. We show that current depth--damage functions consist of disparate relationships that match poorly with observations. Observed flood losses are not monotonic functions of depth, but instead better follow a beta function, with bimodal distributions for different water depths. Uncertainty in flood losses has been called the main bottleneck in flood risk studies, an obstacle that may be remedied using large-scale empirical flood damage data.}
}

@article{zarekariziNeglectingUncertaintiesBiases2020b,
  title = {Neglecting {{Uncertainties Biases House-Elevation Decisions}} to {{Manage Riverine Flood Risks}}},
  author = {Zarekarizi, Mahkameh and Srikrishnan, Vivek and Keller, Klaus},
  year = {2020},
  month = oct,
  journal = {Nature Communications},
  volume = {11},
  number = {1},
  pages = {5361},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-19188-9},
  urldate = {2020-10-26},
  abstract = {Homeowners around the world elevate houses to manage flood risks. Deciding how high to elevate a house poses a nontrivial decision problem. The U.S. Federal Emergency Management Agency (FEMA) recommends elevating existing houses to the Base Flood Elevation (the elevation of the 100-year flood) plus a freeboard. This recommendation neglects many uncertainties. Here we analyze a case-study of riverine flood risk management using a multi-objective robust decision-making framework in the face of deep uncertainties. While the quantitative results are location-specific, the approach and overall insights are generalizable. We find strong interactions between the economic, engineering, and Earth science uncertainties, illustrating the need for expanding on previous integrated analyses to further understand the nature and strength of these connections. Considering deep uncertainties surrounding flood hazards, the discount rate, the house lifetime, and the fragility can increase the economically optimal house elevation to values well above FEMA's recommendation.}
}
